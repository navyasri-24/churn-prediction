# -*- coding: utf-8 -*-
"""churn

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1biqjWMrl3eoN_RBAMHKixnPnC44btqrz
"""

import numpy as np
import pandas as pd

df=pd.read_csv("/content/cp.csv")
df

df.head()

df.shape

df.columns

df.dtypes

# Printing Unique Values of the categorical variables
print(df['Geography'].unique())
print(df['Gender'].unique())
print(df['NumOfProducts'].unique())
print(df['HasCrCard'].unique())
print(df['IsActiveMember'].unique())

# Checking if there are null values or not
df.isnull().sum()

df.describe()

df.head()

# Including only Potential Predictors as independent varibles
final_dataset = df[['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember','EstimatedSalary']]

final_dataset.head()

# Converting the categorical variables into numerical and avoiding Dummy Varibale Trap
final_dataset = pd.get_dummies(final_dataset, drop_first=True)

final_dataset.head()

import seaborn as sns

sns.pairplot(final_dataset)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

# Plotting The Correlations between all the features
corrmat = final_dataset.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20,20))
sns.heatmap(final_dataset[top_corr_features].corr(), annot=True, cmap='RdYlGn')

final_dataset.head()

# Splitting the Dataset into Dependent and Independent Variables
X = final_dataset.iloc[:, [0,1,2,3,4,5,6,7,8,9]]
y = final_dataset.iloc[:, 10].values

X.head()

y

# Splitting the dataset into Training and Testing Data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state = 42)

# Standardizing the Dataset
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

print(X_train)

## Feature Importance
from sklearn.ensemble import ExtraTreesRegressor
model = ExtraTreesRegressor()
model.fit(X,y)

print(model.feature_importances_)

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)

from sklearn.metrics import accuracy_score, confusion_matrix
cm = confusion_matrix(y_test,y_pred)
print(cm)
print(accuracy_score(y_test,y_pred))

# pickling the Model
import pickle
file = open('Customer_Churn_Prediction.pkl', 'wb')
pickle.dump(rf, file)

import sklearn as sh
print(sh.__version__)

from IPython.display import Image
Image(url="https://www.google.com/imgres?imgurl=https%3A%2F%2Fdaxg39y63pxwu.cloudfront.net%2Fimages%2Fblog%2Fchurn-models%2FCustomer_Churn_Prediction_Models_in_Machine_Learning.png&tbnid=3j1GQSNNX6bllM&vet=12ahUKEwist_i21NaBAxXrSGwGHZ9nCc4QMygCegQIARBr..i&imgrefurl=https%3A%2F%2Fwww.projectpro.io%2Farticle%2Fchurn-models%2F709&docid=n8tJT-aNut6L1M&w=2084&h=1250&q=churn%20prediction%20images&ved=2ahUKEwist_i21NaBAxXrSGwGHZ9nCc4QMygCegQIARBr")